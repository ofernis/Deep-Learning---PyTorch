{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Part 4: Linear Regression\n",
    "<a id=part4></a>\n",
    "$\n",
    "\\newcommand{\\mat}[1]{\\boldsymbol {#1}}\n",
    "\\newcommand{\\mattr}[1]{\\boldsymbol {#1}^\\top}\n",
    "\\newcommand{\\matinv}[1]{\\boldsymbol {#1}^{-1}}\n",
    "\\newcommand{\\vec}[1]{\\boldsymbol {#1}}\n",
    "\\newcommand{\\vectr}[1]{\\boldsymbol {#1}^\\top}\n",
    "\\newcommand{\\diag}{\\mathop{\\mathrm {diag}}}\n",
    "\\newcommand{\\set}[1]{\\mathbb {#1}}\n",
    "\\newcommand{\\norm}[1]{\\left\\lVert#1\\right\\rVert}\n",
    "\\newcommand{\\pderiv}[2]{\\frac{\\partial {#1}}{\\partial {#2}}}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part we'll perform the classic machine learning task of linear regression.\n",
    "We'll do some simple data exploration and feature engineering, \n",
    "like in the pre-deep-learning days.\n",
    "Our solution will be implemented using some very widely used machine-learning python libraries \n",
    "([`numpy`](https://docs.scipy.org/doc/numpy-1.15.1/reference/),\n",
    "[`scikit-learn`](http://scikit-learn.org/stable/documentation.html) and\n",
    "[`pandas`](http://pandas.pydata.org/pandas-docs/stable/)).\n",
    "We'll then explore the generalization capacity of the model and perform cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import unittest\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "np.random.seed(42)\n",
    "test = unittest.TestCase()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Dataset exploration\n",
    "<a id=part4_1></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be working with the [Boston housing dataset](http://scikit-learn.org/stable/datasets/index.html#boston-dataset). This is a famous toy dataset for benchmarking regression algorithms.\n",
    "\n",
    "The dataset contains 506 samples of median house values in Boston, each with 13 associated house and neighborhood attributes (features; see link for their meaning).\n",
    "The 13 features of each house are our independent variables, and  we're trying to predict the value of `MEDV`, the median house price (in units of $1000).\n",
    "\n",
    "Run the following block to load the data. Since this dataset is very small, we can load it directly into memory and forgo any lazy-loading mechanisms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets\n",
    "import warnings\n",
    "\n",
    "# Load data we'll work with - Boston housing dataset\n",
    "# We'll use sklearn's built-in data\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "    ds_boston = sklearn.datasets.load_boston()\n",
    "\n",
    "feature_names = list(ds_boston.feature_names)\n",
    "\n",
    "n_features = len(feature_names)\n",
    "x, y = ds_boston.data, ds_boston.target\n",
    "n_samples = len(y)\n",
    "print(f'Loaded {n_samples} samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use `pandas` to visualize the independent and target variables.\n",
    "We'll just show the first 10 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load into a pandas dataframe and show some samples\n",
    "df_boston = pd.DataFrame(data=x, columns=ds_boston.feature_names)\n",
    "df_boston = df_boston.assign(MEDV=y)\n",
    "df_boston.head(10).style.background_gradient(subset=['MEDV'], high=1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore the data a bit by plotting a scatter matrix of every variable as a function of every other and a histogram for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.plotting.scatter_matrix(df_boston, figsize=(20,20));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above chart shows us (among other things) how our target variable `MEDV` behaves as a function\n",
    "of the features (bottom row). By looking at it, can you guess which relationships might be good candidates for a linear model?\n",
    "\n",
    "Let's use a simple method for deciding which features to use for our linear model:\n",
    "the [correlation coefficient](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient),\n",
    "defined as\n",
    "\n",
    "$$\n",
    "\\rho_{\\vec{x}\\vec{y}}\n",
    "= \\frac{\\sigma_{\\vec{x}\\vec{y}}}{\\sigma_{\\vec{x}} \\sigma_{\\vec{y}}}\n",
    "= \\frac\n",
    "    {\\sum_{i=1}^{N} (x_i - \\mu_\\vec{x}) (y_i - \\mu_\\vec{y}) }\n",
    "    {\\sqrt{\\sum_{i=1}^{N} (x_i - \\mu_\\vec{x})^2} \\cdot \\sqrt{\\sum_{i=1}^{N} (y_i - \\mu_\\vec{y})^2}}\n",
    "$$\n",
    "\n",
    "Where $\\vec{x}, \\vec{y}$ are $N$ samples of two variables and $\\mu, \\sigma$ refer to **sample** means and (co-)variances respectively.\n",
    "The value of $\\rho$ is $\\pm 1$ for perfect positive or negative linear relationships ($y=ax+b$),\n",
    "and somewhere in between when it's not perfect.\n",
    "Note that this coefficient is rather limited: even when $\\rho=0$, the variables may be highly dependent,\n",
    "just not in  a linear fashion.\n",
    "\n",
    "Let's implement this method to find out which features we should include in our initial linear model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** Implement the `top_correlated_features()` function in the `hw1/linear_regression.py` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hw1.linear_regression as hw1linreg\n",
    "\n",
    "n_top_features = 5\n",
    "top_feature_names, top_corr = hw1linreg.top_correlated_features(df_boston, 'MEDV', n_top_features)\n",
    "print('Top features: ', top_feature_names)\n",
    "print('Top features correlations: ', top_corr)\n",
    "\n",
    "# Tests\n",
    "test.assertEqual(len(top_feature_names), n_top_features)\n",
    "test.assertEqual(len(top_corr), n_top_features)\n",
    "test.assertAlmostEqual(np.sum(np.abs(top_corr)), 2.893, delta=1e-3) # compare to precomputed value for n=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Model\n",
    "<a id=part4_2></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arguably the simplest machine learning model is linear regression.\n",
    "We are given a dataset $\\left\\{\\vec{x}^{(i)}, y^{(i)}\\right\\}_{i=1}^{N}$ where $\\vec{x}^{(i)} \\in \\set{R}^D$\n",
    "is a $D$-dimensional feature vector and $y^{(i)}\\in\\set{R}$ is a continuous quantity assumed to be the\n",
    "output of some unknown function, i.e. $y^{(i)} = f(\\vec{x}^{(i)})$.\n",
    "\n",
    "Our goal will be to fit a linear transformation,\n",
    "parametrized by weights vector and bias term $\\vec{w}, b$, such that given a sample $\\vec{x}$ our prediction is \n",
    "\n",
    "$$\n",
    "\\hat{y} = \\vectr{w}\\vec{x} + b.\n",
    "$$\n",
    "\n",
    "We'll judge the performance of the model using the ordinary least-squares sense,\n",
    "i.e. with a loss function of given by the mean-squared error (MSE) with the addition\n",
    "of an L2-regularization term:\n",
    "$$\n",
    "L(\\vec{w})\n",
    "= \\frac{1}{2N} \\sum_{i=1}^{N} \\left( y^{(i)} - \\hat{y}^{(i)} \\right)^2 + \\frac{\\lambda}{2}\\norm{\\vec{w}}^2_2\n",
    "= \\frac{1}{2N} \\sum_{i=1}^{N} \\left( y^{(i)} - \\vectr{w}\\vec{x}^{(i)} - b \\right)^2 + \\frac{\\lambda}{2}\\norm{\\vec{w}}^2_2.\n",
    "$$\n",
    "\n",
    "Minimizing the above $L(\\vec{w})$ is a simple convex optimization problem\n",
    "with a closed-form solution. Of course, this can also be solved using iterative descent methods which\n",
    "are necessary when the data is too large to fit in memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a warm up with `numpy`, let's implement the bias trick again (this time using `numpy` and as a `sklearn` transformation)\n",
    "so that our linear regression model will operate on data with an added bias term.\n",
    "\n",
    "**TODO** Implement the class `BiasTrickTransformer` in the `hw1/linear_regression.py` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test BiasTrickTransformer\n",
    "bias_tf = hw1linreg.BiasTrickTransformer()\n",
    "\n",
    "test_cases = [\n",
    "    np.random.randint(10, 20, size=(5,2)),\n",
    "    np.random.randn(10, 1),\n",
    "]\n",
    "\n",
    "for xt in test_cases:\n",
    "    xb = bias_tf.fit_transform(xt)\n",
    "    print(xb.shape)\n",
    "    \n",
    "    test.assertEqual(xb.ndim, 2)\n",
    "    test.assertTrue(np.all(xb[:,0] == 1))\n",
    "    test.assertTrue(np.all(xb[:, 1:] == xt))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets now define a function to assess the accuracy of our models prediction (loss and score).\n",
    "We'll use the MSE loss as above and\n",
    "[$R^2$](https://en.wikipedia.org/wiki/Coefficient_of_determination)\n",
    "as a score. Note that $R^2$ is a number in the range \\[0, 1\\] which represents how much better the regression fits the data in compared to a simple average of the data. It is given by\n",
    "$$\n",
    "R^2 = 1-\\frac{\\sum_i (e^{(i)})^2}{\\sum_i (y^{(i)} - \\bar{y})^2},\n",
    "$$\n",
    "where $e^{(i)} = y^{(i)} - \\hat{y}^{(i)}$ is known as the **residual** for each sample $i$ and $\\bar{y}$ is the data mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** Implement the `mse_score` and `r2_score` function in the `hw1/linear_regression.py` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(y: np.ndarray, y_pred: np.ndarray):\n",
    "    \"\"\"\n",
    "    Calculates mean squared error (MSE) and coefficient of determination (R-squared).\n",
    "    :param y: Target values.\n",
    "    :param y_pred: Predicted values.\n",
    "    :return: A tuple containing the MSE and R-squared values.\n",
    "    \"\"\"\n",
    "    mse = hw1linreg.mse_score(y, y_pred)\n",
    "    rsq = hw1linreg.r2_score(y, y_pred)\n",
    "    return mse, rsq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, these measures and many others are built-in to `sklearn`. We'll use these to test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score as r2, mean_squared_error as mse\n",
    "\n",
    "for i in range(10):\n",
    "    test_y = np.random.randn(20)\n",
    "    test_y_pred = np.random.randn(20)\n",
    "    \n",
    "    mse_actual, r2_actual = evaluate_accuracy(test_y, test_y_pred)\n",
    "    mse_expected, r2_expected = mse(test_y, test_y_pred), r2(test_y, test_y_pred)\n",
    "    \n",
    "    test.assertAlmostEqual(mse_actual, mse_expected, delta=1e-6)\n",
    "    test.assertAlmostEqual(r2_actual, r2_expected, delta=1e-6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can implement our model.\n",
    "\n",
    "**TODO** Based on the above equations for the model and loss, implement the `predict()` and `fit()`\n",
    "functions in the `LinearRegressor` class within the module `linear_regression.py`.\n",
    "You'll need to first derive the closed-form solution for the optimal $\\vec{w}$ based on the loss.\n",
    "Run the code block below to fit your model to each of the 5 top\n",
    "features you selected (one at a time)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A very useful feature of `sklearn` is pipelines: We can create a composite model made of multiple\n",
    "steps which transform the features (using `fit_transform`) and a final step which calculates the actual \n",
    "model predictions (using `fit_predict()`). Each step in the pipeline should be an `sklearn` `Estimator`\n",
    "instance and implement the appropriate methods.\n",
    "\n",
    "For example, lets create a pipeline that scales each input feature to zero-mean and unit variance, applies our bias-trick transformation and finally uses our Linear Regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.preprocessing\n",
    "import sklearn.pipeline\n",
    "\n",
    "# Create our model as a pipline:\n",
    "# First we scale each feature, then the bias trick is applied, then the regressor\n",
    "model = sklearn.pipeline.make_pipeline(\n",
    "    sklearn.preprocessing.StandardScaler(),\n",
    "    hw1linreg.BiasTrickTransformer(),\n",
    "    hw1linreg.LinearRegressor(),\n",
    ")\n",
    "\n",
    "# Test the model implementation is correct\n",
    "y_pred = model.fit_predict(x, y)\n",
    "full_dataset_mse, _ = evaluate_accuracy(y, y_pred)\n",
    "test.assertEqual(y_pred.shape, y.shape)\n",
    "test.assertAlmostEqual(full_dataset_mse, 22.660, delta=1e-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here we'll use our pipleline as a model. \n",
    "\n",
    "We want to now check the predictive power of different features.\n",
    "First, we'll implement a small helper function that will allow us to fit a model on a subset of features from our dataframe.\n",
    "\n",
    "**TODO** Implement the `fit_predict_dataframe` function in the `linear_regression.py` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full dataset\n",
    "y_pred = hw1linreg.fit_predict_dataframe(\n",
    "    model, df_boston, target_name='MEDV'\n",
    ")\n",
    "test.assertAlmostEqual(full_dataset_mse, evaluate_accuracy(y,y_pred)[0], delta=1e-1)\n",
    "\n",
    "# Subset of features\n",
    "y_pred = hw1linreg.fit_predict_dataframe(\n",
    "    model, df_boston, target_name='MEDV', feature_names=['CHAS', 'B']\n",
    ")\n",
    "test.assertAlmostEqual(72.982, evaluate_accuracy(y,y_pred)[0], delta=1e-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use each feature separately and fit multiple\n",
    "times to get an idea of the predictive power of each of our top-5 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=n_top_features, sharey=True, figsize=(20,5))\n",
    "actual_mse = []\n",
    "\n",
    "# Fit a single feature at a time\n",
    "for i, feature_name in enumerate(top_feature_names):\n",
    "    y_pred = hw1linreg.fit_predict_dataframe(model, df_boston, 'MEDV', [feature_name])\n",
    "    mse, rsq = evaluate_accuracy(y, y_pred)\n",
    "\n",
    "    # Plot\n",
    "    xf = df_boston[feature_name].values.reshape(-1, 1)\n",
    "    x_line = np.arange(xf.min(), xf.max(), 0.1, dtype=float).reshape(-1, 1)\n",
    "    y_line = model.predict(x_line)\n",
    "    ax[i].scatter(xf, y, marker='o', edgecolor='black')\n",
    "    ax[i].plot(x_line, y_line, color='red', lw=2, label=f'fit, $R^2={rsq:.2f}$')\n",
    "    ax[i].set_ylabel('MEDV')\n",
    "    ax[i].set_xlabel(feature_name)\n",
    "    ax[i].legend(loc='upper right')\n",
    "    \n",
    "    actual_mse.append(mse)\n",
    "\n",
    "# Test regressor implementation\n",
    "print(actual_mse)\n",
    "expected_mse = [38.862, 43.937, 62.832, 64.829, 66.040]\n",
    "for i in range(len(expected_mse)):\n",
    "    test.assertAlmostEqual(expected_mse[i], actual_mse[i], delta=1e-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the results are not great. We can't reliably predict the target variable based on just one of these.\n",
    "Now let's fit a model based on the combined top-5 features.\n",
    "Since it's difficult to visualize high-dimensional hyperplanes,\n",
    "instead of plotting the data and fitted hyperplane, we'll create a **residuals** plot. This is the plot of the error, or residual $e^{(i)} = y^{(i)} - \\hat{y}^{(i)}$ vs. the predicted value $\\hat{y}^{(i)}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit top-5 features\n",
    "y_pred = hw1linreg.fit_predict_dataframe(model,  df_boston, 'MEDV', top_feature_names)\n",
    "mse5, rsq5 = evaluate_accuracy(y, y_pred)\n",
    "print(f'mse5={mse5:.2f}, rsq5={rsq5:.2f}')\n",
    "\n",
    "# Residuals plot\n",
    "def plot_residuals(y, y_pred, ax=None, res_label=None):\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots()\n",
    "    res = y - y_pred\n",
    "    ax.scatter(y_pred, y_pred-y, marker='s', edgecolor='black', label=res_label)\n",
    "    ax.hlines(y=0, xmin=y_pred.min(), xmax=y_pred.max(), color='red', lw=3)\n",
    "    ax.hlines(y=[-res.std(), res.std()], xmin=y_pred.min(), xmax=y_pred.max(), color='red', lw=3, linestyles=':')\n",
    "    ax.set_xlabel(r'$\\hat{y}$')\n",
    "    ax.set_ylabel(r'$y - \\hat{y}$')\n",
    "    if res_label is not None:\n",
    "        ax.legend()\n",
    "    return ax\n",
    "\n",
    "plot_residuals(y, y_pred)\n",
    "\n",
    "# Sanity test\n",
    "test.assertLess(mse5, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's better, but there's still more to be desired. Let's try to improve our model further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding nonlinear features\n",
    "<a id=part4_3></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that from the scatter matrix that some of the relationships between our features\n",
    "and target variable are obviously not linear and cannot be modeled completely by fitting lines\n",
    "(or hyperplanes).\n",
    "Is there a way to fit a non-linear function to the data (such as a polynomial)\n",
    "but still use the simplicity of the Linear Regression model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we have 2-dimensional feature vectors, $\\vec{x}=(x_1, x_2)$.\n",
    "We can fit a linear regression model with 3 parameters which represents some 2-d plane.\n",
    "However if we transform each such feature vector, for example by\n",
    "$\\vec{\\tilde{x}} = (x_1, x_2, x_1^2, x_1 x_2, x_2^2)$,\n",
    "then we can now fit a model with 6 parameters to the same data.\n",
    "We can thus increase the **capacity** of our model\n",
    "(its ability to fit a wide variety of functions)\n",
    "by adding more parameters that correspond to non-linear transformations of the features. \n",
    "\n",
    "Let's implement some hand-crafted nonlinear features based on all the features in the dataset.\n",
    "This step in the machine learning process is sometimes also referred to as **feature engineering**.\n",
    "In the rest of the course, you'll see how Deep Learning\n",
    "allows us to learn the features themselves instead of creating them by hand, and thus creating very\n",
    "powerful representations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** Implement the `BostonFeaturesTransformer` class in the `hw1/linear_regression.py` module.\n",
    "You can create any features you want, for example given $\\vec{x}=(x_1,x_2)$ you could generate features\n",
    "such as $x_1^2$, $x_1 \\log{x_2}$,  $e^{-x_1}$ and so on.\n",
    "Try to \"engineer\" features by inferring relationships based on the scatter matrix.\n",
    "\n",
    "Notes:\n",
    "- You can use the class `PolynomialFeatures` from `sklearn.preprocessing`\n",
    "  to simplify generation of polynomial features.\n",
    "- Removing a feature is also a new feature. You can and should discard features if they're not helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linreg_boston(model, x, y, fit=True):\n",
    "    if fit:\n",
    "        model.fit(x, y)\n",
    "    y_pred = model.predict(x)\n",
    "    mse, rsq = evaluate_accuracy(y, y_pred)\n",
    "    return y_pred, mse, rsq\n",
    "\n",
    "# Fit with all features this time\n",
    "x = df_boston[feature_names].values\n",
    "\n",
    "# Use model with a custom features transform\n",
    "model = sklearn.pipeline.make_pipeline(\n",
    "    hw1linreg.BiasTrickTransformer(),\n",
    "    hw1linreg.BostonFeaturesTransformer(),\n",
    "    hw1linreg.LinearRegressor()\n",
    ")\n",
    "\n",
    "y_pred, mse, rsq = linreg_boston(model, x, y)\n",
    "plot_residuals(y, y_pred)\n",
    "\n",
    "# Test: You should get at least 2x lower loss than previously, easily even lower\n",
    "print(f'target_mse={mse5/2:.3f}')\n",
    "print(f'mse={mse:.2f}, rsq={rsq:.2f}')\n",
    "test.assertLess(mse, mse5 / 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generalization\n",
    "<a id=part4_4></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By now, your model should produce fairly accurate predictions.\n",
    "Note howerver that we trained it on the entire Boston dataset.\n",
    "\n",
    "When training models, we don't actually care about their performance on the training data;\n",
    "we're not interested in solving optimization problems.\n",
    "What we want is the ability to **generalize**: How well will it perform on novel, unseen data?\n",
    "In other words, did the model learn some function similar to the one actually generating the samples?\n",
    "\n",
    "Let's find out how good our model is for unseen data the usual way: We'll split our dataset into a training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Data and model\n",
    "x = df_boston[feature_names].values\n",
    "y = df_boston['MEDV'].values\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "model = sklearn.pipeline.make_pipeline(\n",
    "    hw1linreg.BiasTrickTransformer(),\n",
    "    hw1linreg.BostonFeaturesTransformer(),\n",
    "    hw1linreg.LinearRegressor()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, instead of just fitting the model on the training set and evaluating on the test set,\n",
    "we'll use cross-validation to find a set of model hyperparameters that allow the model to generalize well.\n",
    "\n",
    "We'll again use k-fold CV to split the training set into k-folds where for each set of\n",
    "hyperparameters being tested, each time one of the folds is treated like the test set and\n",
    "the model is fitted to the rest. However, this time we have more hyperparameters to test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** Implement the `cv_best_hyperparams()` function in the `hw1/linear_regression.py` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define search-spaces for hyper parameters\n",
    "degree_range = np.arange(1, 4)\n",
    "lambda_range = np.logspace(-3, 2, base=10, num=20)\n",
    "\n",
    "# Use cross-validation to find best combination of hyperparameters\n",
    "best_hypers = hw1linreg.cv_best_hyperparams(\n",
    "    model, x_train, y_train, k_folds=3,\n",
    "    degree_range=degree_range, lambda_range=lambda_range\n",
    ") \n",
    "\n",
    "print('Best hyperparameters: ', best_hypers)\n",
    "\n",
    "# Make sure returned params exist in the model\n",
    "for param in best_hypers.keys():\n",
    "    test.assertIn(param, model.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets use the best hyperparameters to train a model on the training set and evaluate it on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the best hyperparameters\n",
    "model.set_params(**best_hypers)\n",
    "\n",
    "# Train best model on full training set\n",
    "y_pred_train, mse, rsq = linreg_boston(model, x_train, y_train)\n",
    "print(f'train: mse={mse:.2f}, rsq={rsq:.2f}')\n",
    "ax = plot_residuals(y_train, y_pred_train, res_label='train')\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred_test, mse, rsq = linreg_boston(model, x_test, y_test, fit=False)\n",
    "print(f'test:  mse={mse:.2f}, rsq={rsq:.2f}')\n",
    "ax = plot_residuals(y_test, y_pred_test, ax=ax, res_label='test')\n",
    "\n",
    "# Make sure test-set accuracy is good\n",
    "test.assertLess(mse, 20) # You should be able to get way below this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "**TODO** Answer the following questions. Write your answers in the appropriate variables in the module `hw1/answers.py`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cs236781.answers import display_answer\n",
    "import hw1.answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1 \n",
    "\n",
    "Whats the ideal pattern to see in a residual plot?\n",
    "Based on the residual plots you got above, what can you say about the fitness of the trained model?\n",
    "Compare the plot for the top-5 features with the final plot after CV.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_answer(hw1.answers.part4_q1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2 \n",
    "\n",
    "Explain the effect of adding non-linear features to our data.\n",
    "\n",
    "1. Is this still a linear regression model? Why or why not?\n",
    "2. Can we fit any non-linear function of the original features with this approach?\n",
    "3. Imagine a linear classification model. As we saw in Part 3, the parameters $\\mat{W}$ of such a model define a hyperplane representing the decision boundary. How would adding non-linear features affect the decision boundary of such a classifier? Would it still be a hyperplane? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_answer(hw1.answers.part4_q2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regarding the cross-validation:\n",
    "\n",
    "1. When defining the range for $\\lambda$ the in the above CV code, why do you think we used\n",
    "   `np.logspace` instead of `np.linspace`? Explain the advantage for CV.\n",
    "1. How many times in total was the model fitted to data (with the parameters as given, and not including the final fit on the entire training set)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_answer(hw1.answers.part4_q3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
